"""
tavily_client.py
────────────────────────────────────────────────────────────
Purpose:
    Handles ALL communication with the Tavily API.

Why This File Exists:
    This isolates external web retrieval logic from the rest of
    the system. The pipeline never calls Tavily directly —
    it only calls functions defined here.

    If you switch providers later, only this file changes.

Pipeline Role:
    Used during the WEB INGESTION stage when no reusable vector
    summary matches the current sub-query.
"""

import os
from tavily import TavilyClient
from urllib.parse import urlparse


# --------------------------------------------------
# Tavily API Client (initialized once)
# --------------------------------------------------
# The API key must be set in environment variables:
# TAVILY_API_KEY
_tavily = TavilyClient(
    api_key=os.getenv("TAVILY_API_KEY")
)


# --------------------------------------------------
# Web Search
# --------------------------------------------------
def tavily_search(
    query: str,
    max_results: int = 3,
):
    """
    Performs a Tavily web search.

    Inputs:
        query:
            Academic-style search query generated by the system.

        max_results:
            Number of top search results to return.

    Returns:
        List of result dictionaries. Each typically contains:
            {
                "url": source URL,
                "score": Tavily relevance score
            }

    Notes:
        • Raw page content is NOT retrieved here.
        • This stage only discovers candidate URLs.
    """
    response = _tavily.search(
        query=query,
        search_depth="advanced",
        max_results=max_results,
        include_raw_content=False,   # content fetched separately
        include_answer=False,
    )
    return response.get("results", [])


# --------------------------------------------------
# Content Extraction
# --------------------------------------------------
def tavily_extract(url: str):
    """
    Extracts the full raw text content of a webpage.

    Inputs:
        url:
            URL selected during search stage.

    Returns:
        Dictionary containing:
            {
                "url": URL,
                "domain": domain name,
                "raw_text": full page text,
                "published_date": optional metadata from Tavily
            }

        Returns None if extraction fails.

    Notes:
        • This is the step that actually downloads page text.
        • The returned raw_text is later filtered, truncated,
          and summarized by the LLM.
    """
    response = _tavily.extract(
        urls=[url],
        include_raw_content=True,
    )

    data = response.get("results", [])
    if not data:
        return None

    item = data[0]

    # Normalize domain for scoring & metadata
    domain = urlparse(url).netloc.replace("www.", "")

    return {
        "url": url,
        "domain": domain,
        "raw_text": item.get("raw_content") or item.get("content"),
        "published_date": item.get("published_date"),
    }
